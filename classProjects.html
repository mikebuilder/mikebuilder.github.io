<html><head>
  <title>Michael Abadjiev</title>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="images/interests/2001 final render.JPG">
<body>

	<h1>
	<br/>MICHAEL&nbspABADJIEV
	</h1>
	<div class="menu">
	<a href="index.html" class="internal">
	Home
	&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
	<a href="about.html" class="internal">
	About
	</a>
	&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
	<a href="Resume.html"  class="internal">
	Resume
	</a>
	&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
	<div class="dropdown">
			<span class="dropbtn"><b>Projects</b></span>
			<div class="dropdown-content">
				<a href="classProjects.html">Class Projects</a>
				<!-- <a href="clubProjects.html">Club Projects</a> -->
				<a href="Lionfish.html">Lionfish Hunting</a>
				<a href="FSAE.html">Formula SAE</a>
				<!-- <a href="personalProjects.html">Personal Projects</a> -->
			</div>
	</div>
	&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
	<a href="gallery.html"  class="internal">
	Gallery
	</a>
	<!-- <div class="dropdown">
			<span class="dropbtn">Gallery</span>
			<div class="dropdown-content">
				<a href="gallery.html">Projects Gallery</a>
				<a href="interests.html">Interests Gallery</a>
			</div>
	</div> -->
	<br/>
	</div>
	<hr color="lightslategray"></hr>
	
	</div>
	
	<!--ME 4815-->
	<a href="gallery.html#ME4815" class="project">
	<table>
		<tbody><tr>
			<td colspan="3" align="left" valign="middle"> 
				<div class="projectHeader">Industrial Robotics (ME 4815)</div>
				<div class="projectDate">October 2019 - December 2019</div>
			</td>
		</tr>
		<tr>
			<td>
				<!-- <iframe width="400" height="225" src="C:\Users\micha\Desktop\mike\work applications\website git\PersonalWebsite\images\ME 4815\C0062.MP4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
				<video width = "400" controls>
					<source src="images\ME 4815\C0062.MP4" type="video/mp4"> Your browser does not support the video tag.
				</video>
			</td>
			<td class="projectTools"> 
				&nbsp; <u><b>Tools used</b></u> <br>
					<ul class="tools">
						<li> ABB RobotStudio</li>
						<li> SolidWorks </li>
						<li> MATLAB </li>

						
					</ul>
			</td>
			<td class="projectDescription">
				<u><b>Description</b></u><br>
					&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<!--indent first line-->
					ME 4815 Focuses on introducing students to programming and designign tooling for industrial robots.
					For the final project for this class, my team and I created functionality for a 6-axis ABB IRB1600 arm to "paint" a picture using LEGO bricks.
					A MATLAB script is first used to parse an image, reducing it in size and simplfying the colors to fit within our limited pallette of bricks.
					This is automatically sent from the control computer to a script running on the robot controller to place blocks line by line.
					I was responsible for the limited mechanical design required for this project, as well as the RobotStudio programming.
					
					<br>
					<br>
					Project report download:
					<a href="documents/Final Report Team 1 B19.pdf" class="download"> Click here </a>
			</td>
		</tr>
	</tbody></table>
	</a>

	<!--ME 4320-->
	<a href="gallery.html#ME4320" class="project">
	<table>
		<tbody><tr>
			<td colspan="3" align="left" valign="middle"> 
				<div class="projectHeader">Advanced Engineering Design (ME 4320)</div>
				<div class="projectDate">August 2019 - October 2019</div>
			</td>
		</tr>
		<tr>
			<td>
				<img src="images\ME 4320\iso render.JPG" width="400"></img>
			</td>
			<td class="projectTools"> 
				&nbsp; <u><b>Tools used</b></u> <br>
					<ul class="tools">
						<li> SolidWorks </li>
						<li> Laser Cutter </li>
						<li> 3D printer </li>
						<li> GrabCAD Workbench </li>
						
					</ul>
			</td>
			<td class="projectDescription">
				<u><b>Description</b></u><br>
					&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<!--indent first line-->
					For this project, we we charged by iRobot to develop a device for testing their Roomba vacuum cleaners.
					The device was required to generate and dispense wisps of cotton to simulate human and pet hair.
					I was the primary mechanical designer for our sandpaper driven "wispifier", which uses a sanding belt to tear wisps off of bulk cotton, which are then dispensed by means of a blower fan.
					We achieved success with "wispifying" cotton, and produced a density similar to human hair, as was desired by iRobot, 
					however we struggled with removing the hair from the sandpaper.
					
					
					<br>
					<br>
					Project report download:
					<a href="documents/MAbadjiev_ME4320_Final_Report.pdf" class="download"> Click here </a>
			</td>
		</tr>
	</tbody></table>
	</a>

	<!--RBE 3002-->
	<a href="gallery.html#RBE3002" class="project">
	<table>
		<tbody><tr>
			<td colspan="3" align="left" valign="middle"> 
				<div class="projectHeader">Unified Robotics IV (RBE 3002)</div>
				<div class="projectDate">October 2018 - December 2018</div>
			</td>
		</tr>
		<tr>
			<td>
				<iframe width="400" height="225" src="https://www.youtube.com/embed/n_GQZ8FX10Q" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
			</td>
			<td class="projectTools"> 
				&nbsp; <u><b>Tools used</b></u> <br>
					<ul class="tools">
						<li> Github</li>
						<li> Python </li>
						<li> Linux </li>
						<li> ROS Kinetic</li>
						<li> turtlebot burger</li>
					</ul>
			</td>
			<td class="projectDescription">
				<u><b>Description</b></u><br>
					&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<!--indent first line-->
					RBE 3002 is the final course in the robotics sequence at WPI. 
					In this class, we focused on autonomous navigation, with the final project being a full implementation of a simultaneous localization and mapping (SLAM) robot.
					We used the turtlebot 3 burger as the base for this robot, due to the easily available ROS support. 
					Our robot makes use of some of the readily available mapping support for the turtlebot, like the gmapping and monte carlo localization functions which localize the robot within its environment.
					We devloped our own exploration pattern, using our own implementation of the A* search algorithm to travel to the nearest unexplored "frontier" and then proceed to the next, until the entire area is mapped.
					Once the robot has mapped its environment, it enters a state where it waits for a goal location input from the user to determine where to travel to next.
					For detailed descriptions of the ROS nodes we devloped, and flowcharts showing the program operation, check out the final presentation, attached below.

					<br>
					<br>
					Project presentation download:
					<a href="documents/Final Presentation.pdf" class="download"> Click here </a>
			</td>
		</tr>
	</tbody></table>
	</a>

	
	<!--RBE 3001-->
	<a href="gallery.html#RBE3001" class="project">
	<table>
		<tbody><tr>
			<td colspan="3" align="left" valign="middle"> 
				<div class="projectHeader">Unified Robotics III (RBE 3001)</div>
				<div class="projectDate">August 2018 - October 2018</div>
			</td>
		</tr>
		<tr>
			<td class="projectPicture"> 
				<iframe width="400" height="225" src="https://www.youtube-nocookie.com/embed/PaxZjTWr1kE?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
				<!-- <img width="100%" src="images/RBE 3001/rbe3001robot.jpg">  -->
			</td>
			<td class="projectTools"> 
				&nbsp; <u><b>Tools used</b></u> <br>
					<ul class="tools">
						<li> Github</li>
						<li> Matlab </li>
						<li> C++</li>
						<li> Python </li>
						<li> Robot Kinematics</li>
						<li> Linux </li>
						<li> Raspberry Pi</li>
						<li> STM Nucleo</li>
					</ul>
			</td>
			<td class="projectDescription">
				<u><b>Description</b></u><br>
					&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<!--indent first line-->
					In this project, I worked on a team of 3 to implement functionality for a 3 degree of freedom robotic arm to be able to sort objects based on color and weight.
					We used forward and inverse robot kinematics to be able to track the robot's position at any given time, and interpolate from task-space desired locations to the required joint-space positions.
					A trajectory planning algorithm was used to interpolate between desired points and generate smooth paths.
					This, coupled with a PID controller resulted in a smoothly moving robot that was able to sort objects by weight and color.
					Additionally, we chose to implement remote control of the robot, both using voice control to activate it, and a 3D space mouse to operate it.
					<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
					The arm was provided to us a lab material, and uses a STM Nucleo as the robot control board.
					It features servo motors to operate each joint, as well as magnetic encoders and load cells at each joint to report the orientation and measured torque on each link.
					The robot's firmware is written in C++, and was mostly provided by the lab, however, we made some key additions to be able to communicate better with the robot.
					Commands were sent to the robot using Matlab scripts running on a Linux machine in the lab.
					All major computations were kept on the Matlab side, in order to utilize the significantly grater processing power and speed of the lab computers, compared to the Nucleo.
					Finally, a Raspberry Pi acting as an Apple home device, connected to the Matlab machine via a serial connection, was used to enable remote control of the robot.
					<br>
					<br>
					Project report download:
					<a href="documents/RBE 3001 Final Report.pdf" class="download"> Click here </a>
			</td>
		</tr>
	</tbody></table>
	</a>
	
	<!--RBE 2002-->
	<a href="gallery.html#RBE2002" class="project">
	<table>
		<tbody><tr>
			<td colspan="3" align="left" valign="middle"> 
				<div class="projectHeader">Unified Robotics II (RBE 2002)</div>
				<div class="projectDate">March 2018 - May 2018</div>
			</td>
		</tr>
		<tr>
			<td class="projectPicture">
				<iframe width="400" height="225" src="https://www.youtube-nocookie.com/embed/FHoDOtyUmYQ?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>			
				<!-- <img width="100%" src="images/RBE 2002/rbe2002.JPG">  -->
			</td>
			<td class="projectTools"> 
				&nbsp; <u><b>Tools used</b></u> <br>
					<ul class="tools">
						<li> Solidworks </li>
						<li> Laser cutter</li>
						<li> Arduino </li>
						<li> 3D printer</li>
						<li> GrabCad</li>
					</ul>
			</td>
			<td class="projectDescription">
				<u><b>Description</b></u><br>
					&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<!--indent first line-->
					The focus of RBE 2002 at WPI is on sensing and reacting to your environment, and especially dealing with the imperfect information common in any sensor.
					The term project focused on applying what we learned in class to a robot that had to navigate a small maze in search of a candle, and extinguish it.
					The robot had to be able to navigate the entire maze fully autonomosly, and report the location of the candle flame with respect to its original start position at the end of the run.
					To do this, my team used infrared rangefinders on its right side to follow a wall, making only left turns, and a forward-mounted rangefinder to detect any obstacles. 
					While doing this, an array of 16 flame-detection sensors continuously scanned the area, until a flame was detected, indicating that it had entered the same room as the candle.
					Finally, a more finely-tuned sensor on a 2-axis gimbal was used to accurately determine the height of the candle in order to be able to point a high-powered fan at it and extinguish it.
					Additionally, a black-line sensor was mounted on the base of the robot in order to detect and avoid going over an edge and falling off the table.
					In order to keep track of all of these sensors, an I2C interface was used for the rangefinders, and SPI for the flame sensors.
					Additionally, the flame detection sensors were mounted on boards of 4 sensors, which were in turn connected to a main controller board for the flame sensors.
					This allowed us to divide the sensors into sub-packets and determine which one of them detected a flame.
					<br>
					<br>
					Project report download:
					<a href="documents/RBE 2002 Final Report.pdf" class="download"> Click here </a>
			</td>
		</tr>
	</tbody></table>
	</a>
	 
	<!--RBE 2001-->
	<a href="gallery.html#RBE2001" class="project">
	<table>
		<tbody><tr>
			<td colspan="3" align="left" valign="middle"> 
				<div class="projectHeader">Unified Robotics I (RBE 2001)</div>
				<div class="projectDate">Jan 2018 - March 2018</div>
			</td>
		</tr>
		<tr>
			<td class="projectPicture"> 
				<iframe width="400" height="225" src="https://www.youtube-nocookie.com/embed/X8QQ1xWM5Ds?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
				<!-- <img width="100%" src="images/RBE 2001/robot on field final.JPG">  -->
			</td>
			<td class="projectTools"> 
				&nbsp; <u><b>Tools used</b></u> <br>
					<ul class="tools">
						<li> Solidworks </li>
						<li> Motion Studies</li>
						<li> Laser Cutter </li>
						<li> Arduino </li>
						<li> 3D printing</li>
					</ul>
			</td>
			<td class="projectDescription">
				<u><b>Description</b></u><br>
					&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <!--indent first line-->
					This was my term project for RBE 2001: Unified Robotics I.
					The challenge for this project is to work on a team of 3 to design a robot that can autonomously service a "nuclear reactor facility".
					The robot must be able to extract fuel rods from horizontal storage tubes, place them into the vertical reactor tubes, and place used fuel rods into more horizontal containment tubes.
					It is fully autonomous, relying only on information sent via Bluetooth from the Robot Command Station(RCS) which tells the robot which reactor needs fuel, and which storage/containment tubes are empty.
					The robot also sends a periodic  heartbeat message to the RCS to show that it is still functioning.
					<br>
					<br>
					Project report download:
					<a href="documents/RBE 2001 Final Report Team 18.pdf" class="download"> Click here </a>
			</td>
		</tr>
	</tbody></table>
	</a>
	
	<!--CS3733-->
	<a href="gallery.html#CS3733" class="project">
	<table>
		<tbody><tr>
			<td colspan="3" align="left" valign="middle"> 
				<div class="projectHeader">Software Engineering (CS 3733)</div>
				<div class="projectDate">October 2017 - December 2017</div>
			</td>
		</tr>
		<tr>
			<td class="projectPicture"> 
				<img width="100%" src="images/CS3733/main screen.png"> 
			</td>
			<td class="projectTools"> 
				&nbsp; <u><b>Tools used</b></u> <br>
					<ul class="tools">
						<li> Java</li>
						<li> Apache derby database </li>
						<li> Javafx </li>
						<li> Scenebuilder</li>
						<li> Github</li>
					</ul>
			</td>
			<td class="projectDescription">
				<u><b>Description</b></u><br>
					&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <!--indent first line-->
					For CS 3733 Software Engineering, I worked on a team of 10 to develop an application for kiosks in the Brigham and Women's hospital in Boston MA.
					The application provides features to hospital visitors and employees alike, such as animated pathfinding around the hospital, 
					requesting services, a key location finder, a feature for administrators to edit the map etc.
					As the project manager I was responsible for distributing tasks among the team, as well as running our daily scrum meetings.
					I also wrote a large portion of the controller classes for the UI components.
					Some noteworthy features that I worked on include the path animations, the key locations, and the map building UI, which can be acessed from the admin screen.
					<br>
					<br>
					
					Project download (zip containing report, executable jar file, and manual): 
					<a href="documents/CS3733TeamDProject-4.0.zip" class="download"> Click here </a>
					<br>
					<a href="https://github.com/mikebuilder/CS3733TeamDProject" class="external">Github repository</a>

			</td>
		</tr>
	</tbody></table>
	</a>
	
	<!--3D printing ISP-->
	<a href="gallery.html#printer" class="project">
	<table>
		<tbody><tr>
			<td colspan="3"> 
				<div class="projectHeader">Continuous 3D printing ISP</div>
				<div class="projectDate">March 2017 - Nov 2017</div>
			</td>
		</tr>
		<tr>
			<td class="projectPicture"> 
				<a href="gallery.html#3DprintingISP">
					<img width="100%" src="images/3D printing ISP/1.jpg"> 
				</a>
			</td>
			
			<td class="projectTools"> 
				&nbsp; <u><b>Tools used</b></u> <br>
					<ul class="tools">
						<li> Solidworks </li>
						<li> Laser Cutter </li>
						<li> 3D printer </li>
					</ul>
			</td>
			
			<td class="projectDescription">
				<u><b>Description</b></u><br>
					&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <!--indent first line-->
					This was an independant study project (ISP) in which I worked with one other person to develop an add-on for FDM
					3D printers that allows for continuous printing.  The point of this ISP was to serve as a proof of concept for a new
					approach that is simpler and easier to implement than many traditional ideas.  It uses an adaptable vacuum bed
					design, enabled by a shop vac, to hold paper in place while printing, then roles the paper off after each print.
					<br>
					<br>
					<!--
					<u><b> Tools used:</b></u> <br/>
					&nbsp&nbsp&nbsp&nbsp&nbspSolidworks, Laser Cutter, 3D printer
					<br/>
					<br/>
					-->
					Project report download: 
					<a href="documents/3D printing ISP.pdf" class="download"> Click here </a>
		</td></tr>
	</tbody></table>
	</a>
	
	<br><br>
	
	<!--RBE 1001-->
	<a href="gallery.html#RBE1001" class="project">
	<table>
		<tbody><tr>
			<td colspan="3" align="left" valign="middle"> 
				<div class="projectHeader">Introduction to Robotics (RBE 1001)</div>
				<div class="projectDate">Jan 2017 - March 2017</div>
			</td>
		</tr>
		<tr>
			<td class="projectPicture"> 
				<img width="100%" src="images/RBE 1001/RBE 1001 - 1.JPG"> 
			</td>
			<td class="projectTools"> 
				&nbsp; <u><b>Tools used</b></u> <br>
					<ul class="tools">
						<li> Inventor </li>
						<li> Laser Cutter </li>
						<li> Arduino </li>
					</ul>
			</td>
			<td class="projectDescription">
				<u><b>Description</b></u><br>
					&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <!--indent first line-->
					This was my final project for my RBE 1001 introduction to robotics class.  
					For this project I worked on a team of 3 to design and build a robot for WPI's "Savage Soccer" competition. 
					For us, the competition involved moving "eggs" into various scoring locations, as well as a final challenge of hanging the robot off of a horizontal bar.  
					A large part of the project was also an analysis of our robot using equations of static equilibrium to ensure that our design would be robust before buiding it.
					These calculations can be found in detail in the project report, available for download below.				
					<br>
					<br>
					Project report download: 
					<a href="documents/RBE1001.pdf" class="download"> Click here </a>

			</td>
		</tr>
	</tbody></table>
	</a>
			
	
	
	
	

</body></html>